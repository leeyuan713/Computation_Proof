---
title: "Computation Proof for Stat771 Project"
author: "Yuan Li"
date: "May 5th, 2015"
output: pdf_document
---
\section{1. Simulation Setting}
Following is a small simulation study to show how the algorithms in the paper will work. This simulation is similar with that in the paper, but here I use different levels for the values of $p$, and run the simulation on a different machine (Nebula-9 on biostat server). In this simulation I generate data with 20 independent observations distributed as $N(0,\Sigma)$, where $\Sigma$ is a $p\times p$ matrix that takes one of three forms: (1) $\Sigma=\textbf{I}$, (2) $\Sigma$ is a block diagonal matrix with a single $(p/2)\times(p/2)$ block with all off-diagonal elements equal to 0.5, and all diagonal elements of $\Sigma$ equal 1, and (3) all off-diagonal elements of $\Sigma$ equal 0.5 and all diagonal elements equal 1. I use three different values of $p: p=100,800,1500.$ I choose $\lambda$ in each simulation in order to achieve a desired "sparsity level", measured by the fraction of completely unconnected nodes in the graphical lasso solution. The three sparsity levels are 0.2,0.5,0.9. The results for the simulation with three different sparsity levels are as following:
\section{2. Simulation Results}
```{r read_in_results_files,echo=FALSE}
Block1 <- read.table("SimTimesBLOCKDIAGSparsityLevel0.2.txt")
Block2 <- read.table("SimTimesBLOCKDIAGSparsityLevel0.5.txt")
Block3 <- read.table("SimTimesBLOCKDIAGSparsityLevel0.9.txt")
MB1 <- read.table("SimTimesMBSparsityLevel0.2.txt")
MB2 <- read.table("SimTimesMBSparsityLevel0.5.txt")
MB3 <- read.table("SimTimesMBSparsityLevel0.9.txt")
Noscr1 <- read.table("SimTimesNOSCREENINGSparsityLevel0.2.txt")
Noscr2 <- read.table("SimTimesNOSCREENINGSparsityLevel0.5.txt")
Noscr3 <- read.table("SimTimesNOSCREENINGSparsityLevel0.9.txt")
Scr1 <- read.table("SimTimesSCREENINGSparsityLevel0.2.txt")
Scr2 <- read.table("SimTimesSCREENINGSparsityLevel0.5.txt")
Scr3 <- read.table("SimTimesSCREENINGSparsityLevel0.9.txt")
```
```{r construct_results_matrix,echo=FALSE}
### Sparsity Level=0.2
results <- matrix(data=0, nrow=4, ncol=3)
rownames(results) <- c("Original","Algorithm_1","Algorithm_2","MB_Approx")
colnames(results) <- c("Simu_1","Simu_2","Simu_3")
Sparsity2 <- list(results, results, results)
names(Sparsity2) <- c("p=100", "p=800", "p=1500")
for(i in 1:3)
{
 Sparsity2[[i]][1,] <- noquote(as.matrix(Noscr1[i,]))
 Sparsity2[[i]][2,] <- noquote(as.matrix(Scr1[i,]))
 Sparsity2[[i]][3,] <- noquote(as.matrix(Block1[i,]))
 Sparsity2[[i]][4,] <- noquote(as.matrix(MB1[i,]))
}
### Sparsity Level=0.5
results <- matrix(data=0, nrow=4, ncol=3)
rownames(results) <- c("Original","Algorithm_1","Algorithm_2","MB_Approx")
colnames(results) <- c("Simu_1","Simu_2","Simu_3")
Sparsity5 <- list(results, results, results)
names(Sparsity5) <- c("p=100", "p=800", "p=1500")
for(i in 1:3)
{
 Sparsity5[[i]][1,] <- noquote(as.matrix(Noscr2[i,]))
 Sparsity5[[i]][2,] <- noquote(as.matrix(Scr2[i,]))
 Sparsity5[[i]][3,] <- noquote(as.matrix(Block2[i,]))
 Sparsity5[[i]][4,] <- noquote(as.matrix(MB2[i,]))
}
### Sparsity Level=0.9
results <- matrix(data=0, nrow=4, ncol=3)
rownames(results) <- c("Original","Algorithm_1","Algorithm_2","MB_Approx")
colnames(results) <- c("Simu_1","Simu_2","Simu_3")
Sparsity9 <- list(results, results, results)
names(Sparsity9) <- c("p=100", "p=800", "p=1500")
for(i in 1:3)
{
 Sparsity9[[i]][1,] <- noquote(as.matrix(Noscr3[i,]))
 Sparsity9[[i]][2,] <- noquote(as.matrix(Scr3[i,]))
 Sparsity9[[i]][3,] <- noquote(as.matrix(Block3[i,]))
 Sparsity9[[i]][4,] <- noquote(as.matrix(MB3[i,]))
}
```
```{r Show_Resuts}
### Sparsity Level=0.2
noquote(Sparsity2)
### Sparsity Level=0.5
noquote(Sparsity5)
### Sparsity Level=0.9
noquote(Sparsity9)
```
\section{3. Discussion}
First we can see that the speed of Algorithm 1 and Algorithm 2 in this paper is much faster than the original standard graphical lasso algorithm. Moreover we can see that Algorithm 2 is faster than Algorithm 1 in Simulation 1 since the true $\Sigma$ is diagonal the first step in Algorithm 1 is unnecessary. On the other hand we can see that in Simulation 3 Algorithm 1 performs better than Algorithm 2 since in this case the true $\Sigma$ is dense so the connected nodes in the graphical lasso solution mostly belong to a single connected component rather than multiple connected components. These conclusions are consistent with that in the paper.